#!/usr/bin/env python3
"""
Palli Sahayak - Voice AI Demo with Actual TTS Audio
====================================================

Demonstrates:
1. Gemini Live API - Web-based voice conversations
2. Bolna.ai - Phone calls with custom voice agents
3. Retell.ai + Vobiz.ai - Indian PSTN (+91) with SIP-REFER warm handoff
4. WhatsApp Bot - Twilio sandbox integration

Generates ACTUAL audio files using Edge TTS for the demo.
"""

import os
import sys
import asyncio
import json
from datetime import datetime
from pathlib import Path

# Add current directory to path
sys.path.insert(0, str(Path(__file__).parent))

# Color codes for terminal output
class Colors:
    HEADER = '\033[95m'
    BLUE = '\033[94m'
    CYAN = '\033[96m'
    GREEN = '\033[92m'
    WARNING = '\033[93m'
    FAIL = '\033[91m'
    END = '\033[0m'
    BOLD = '\033[1m'
    UNDERLINE = '\033[4m'

def print_header(text):
    print(f"\n{Colors.HEADER}{'='*70}{Colors.END}")
    print(f"{Colors.HEADER}{Colors.BOLD}{text.center(70)}{Colors.END}")
    print(f"{Colors.HEADER}{'='*70}{Colors.END}\n")

def print_section(text):
    print(f"\n{Colors.CYAN}{Colors.BOLD}тЦ╢ {text}{Colors.END}")
    print(f"{Colors.CYAN}{'тФА'*60}{Colors.END}")

def print_success(text):
    print(f"{Colors.GREEN}тЬУ {text}{Colors.END}")

def print_warning(text):
    print(f"{Colors.WARNING}тЪа {text}{Colors.END}")

def print_info(text):
    print(f"{Colors.BLUE}тД╣ {text}{Colors.END}")

def print_audio(text):
    print(f"{Colors.GREEN}ЁЯФК {text}{Colors.END}")

# ============================================================================
# AUDIO GENERATION USING EDGE TTS
# ============================================================================

async def generate_voice_audio(text, language, output_file):
    """Generate actual audio using Edge TTS"""
    try:
        import edge_tts
        
        voices = {
            "hi": "hi-IN-SwaraNeural",
            "en": "en-IN-NeerjaNeural",
            "gu": "gu-IN-DhwaniNeural",
            "bn": "bn-IN-TanishaaNeural",
            "ta": "ta-IN-PallaviNeural",
        }
        
        voice = voices.get(language, "en-IN-NeerjaNeural")
        
        print_info(f"Generating audio with voice: {voice}")
        communicate = edge_tts.Communicate(text, voice)
        await communicate.save(output_file)
        
        file_size = os.path.getsize(output_file)
        print_success(f"Audio generated: {output_file} ({file_size} bytes)")
        return True
        
    except Exception as e:
        print_warning(f"Audio generation failed: {e}")
        return False

# ============================================================================
# DEMO 1: GEMINI LIVE API - WEB VOICE
# ============================================================================

async def demo_gemini_live():
    """Demo Gemini Live API for web-based voice"""
    print_header("DEMO 1: GEMINI LIVE API - WEB VOICE")
    
    print_section("Session Initialization")
    
    session = {
        "session_id": "gemini-live-001",
        "provider": "Gemini Live API",
        "audio_format": "PCM 16-bit 16kHz (input) / 24kHz (output)",
        "language": "hi-IN",
        "max_duration": "15 minutes",
        "connection": "WebSocket (WSS)"
    }
    
    print(f"  Session ID: {session['session_id']}")
    print(f"  Provider: {session['provider']}")
    print(f"  Audio Format: {session['audio_format']}")
    print(f"  Language: {session['language']}")
    
    print_section("WebSocket Connection")
    
    websocket_log = """
    CONNECTING wss://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-exp:streamGenerateContent?key=***
    
    тмЖя╕П  SEND: {
      "setup": {
        "model": "models/gemini-2.0-flash-exp",
        "generation_config": {
          "response_modalities": ["AUDIO"],
          "speech_config": {
            "voice_config": {"prebuilt_voice_config": {"voice_name": "Aoede"}}
          }
        }
      }
    }
    
    тмЗя╕П  RECEIVE: {"setupComplete": {}}
    
    тЬЕ WebSocket connection established
    """
    
    print(websocket_log)
    
    print_section("Patient Query (Voice Input)")
    
    patient_query = "рдорд╛рдБ рдХреЛ рджрд░реНрдж рд╣реИ, рдХреНрдпрд╛ рдХрд░реВрдВ?"  # "Mother has pain, what should I do?"
    print(f"  Patient (Hindi): {patient_query}")
    print(f"  Translated: \"Mother has pain, what should I do?\"")
    
    # Generate audio for patient query
    audio_file = "cache/demo_gemini_patient_query.mp3"
    await generate_voice_audio(
        "рдорд╛рдБ рдХреЛ рджрд░реНрдж рд╣реИ, рдХреНрдпрд╛ рдХрд░реВрдВ?", 
        "hi", 
        audio_file
    )
    print_audio(f"Patient audio: {audio_file}")
    
    print_section("RAG Context Injection")
    
    rag_context = """
    Querying ChromaDB vector store...
    
    Retrieved 3 relevant documents:
    1. WHO Cancer Pain Guidelines (relevance: 0.94)
    2. Max Healthcare Pain Management SOP (relevance: 0.91)
    3. Pallium India Home Care Protocol (relevance: 0.88)
    
    Context injected into Gemini session.
    """
    print(rag_context)
    
    print_section("Gemini Response (Voice Output)")
    
    response_text = """
    рдЖрдкрдХреА рдорд╛рдБ рдХреЛ рджрд░реНрдж рдХреЗ рд▓рд┐рдП рдпреЗ рджрд╡рд╛рдИ рджреЗрдВ:
    
    рдореЛрд░реНрдлрд┐рди 5 рд╕реЗ 10 рдорд┐рд▓реАрдЧреНрд░рд╛рдо,
    рд╣рд░ 4 рдШрдВрдЯреЗ рдореЗрдВ рдПрдХ рдмрд╛рд░ред
    
    рдЕрдЧрд░ рджрд░реНрдж рдмрд╣реБрдд рдЬрд╝реНрдпрд╛рджрд╛ рд╣реЛ,
    рддреЛ рдбреЙрдХреНрдЯрд░ рд╕реЗ рдмрд╛рдд рдХрд░реЗрдВред
    """
    
    print(f"  AI Response (Hindi):")
    for line in response_text.strip().split('\n'):
        print(f"    {line}")
    
    # Generate audio for AI response
    audio_file = "cache/demo_gemini_ai_response.mp3"
    await generate_voice_audio(
        "рдЖрдкрдХреА рдорд╛рдБ рдХреЛ рджрд░реНрдж рдХреЗ рд▓рд┐рдП рдореЛрд░реНрдлрд┐рди 5 рд╕реЗ 10 рдорд┐рд▓реАрдЧреНрд░рд╛рдо, рд╣рд░ 4 рдШрдВрдЯреЗ рдореЗрдВ рдПрдХ рдмрд╛рд░ рджреЗрдВред рдЕрдЧрд░ рджрд░реНрдж рдмрд╣реБрдд рдЬрд╝реНрдпрд╛рджрд╛ рд╣реЛ, рддреЛ рдбреЙрдХреНрдЯрд░ рд╕реЗ рдмрд╛рдд рдХрд░реЗрдВред",
        "hi",
        audio_file
    )
    print_audio(f"AI response audio: {audio_file}")
    
    print_success("Gemini Live demo completed")

# ============================================================================
# DEMO 2: BOLNA.AI - PHONE CALLS
# ============================================================================

async def demo_bolna():
    """Demo Bolna.ai for phone calls"""
    print_header("DEMO 2: BOLNA.AI - PHONE CALLS")
    
    print_section("Call Configuration")
    
    config = {
        "agent_name": "Palli Sahayak - Hindi",
        "phone_number": "+91-XXXX-NH-HELP",
        "language": "hi-IN",
        "asr_provider": "Deepgram (nova-2)",
        "llm_provider": "OpenAI (gpt-4o-mini)",
        "tts_provider": "ElevenLabs (eleven_multilingual_v2)",
        "telephony": "Twilio"
    }
    
    for key, value in config.items():
        print(f"  {key}: {value}")
    
    print_section("Initiating Outbound Call")
    
    call_log = """
    POST https://api.bolna.ai/call
    {
      "agent_id": "palli-sahayak-hi",
      "phone_number": "+919876543210",
      "patient_id": "PT-ONCO-2026-001",
      "context": {
        "name": "Mrs. Lakshmi Devi",
        "medication": "Ondansetron 8mg",
        "purpose": "Chemotherapy nausea prevention"
      }
    }
    
    тмЗя╕П  RESPONSE: {
      "call_id": "call-bol-001",
      "status": "initiated",
      "webhook_url": "https://api.pallisahayak.io/webhook/bolna"
    }
    
    тЬЕ Call initiated successfully
    """
    print(call_log)
    
    print_section("Call Flow (Voice Conversation)")
    
    conversation = [
        ("AI", "рдирдорд╕реНрддреЗ рд▓рдХреНрд╖реНрдореА рдЬреА, рдореИрдВ рдкрд▓реНрд▓реА рд╕рд╣рд╛рдпрдХ рдмреЛрд▓ рд░рд╣рд╛ рд╣реВрдВред"),
        ("Patient", "рдирдорд╕реНрддреЗ..."),
        ("AI", "рдпрд╣ рдЖрдкрдХреА рджрд╡рд╛рдИ рдХрд╛ рд╕рдордп рд╣реИред рдХреГрдкрдпрд╛ рдСрдиреНрдбреЗрд╕реЗрдЯреНрд░реЙрди 8 рдорд┐рд▓реАрдЧреНрд░рд╛рдо рд▓реЗрдВред"),
        ("Patient", "рдареАрдХ рд╣реИ, рдореИрдВ рдЕрднреА рд▓реЗ рд▓реЗрддреА рд╣реВрдВред"),
        ("AI", "рдмрд╣реБрдд рдЕрдЪреНрдЫрд╛ред рджрд╡рд╛рдИ рд▓реЗрдиреЗ рдХреЗ рдмрд╛рдж рдлреЛрди рдкрд░ 1 рджрдмрд╛рдПрдВред"),
        ("System", "[DTMF tone: 1]"),
        ("AI", "рдзрдиреНрдпрд╡рд╛рдж рд▓рдХреНрд╖реНрдореА рдЬреАред рдЕрдЧрд▓реА рджрд╡рд╛рдИ рд╢рд╛рдо 8 рдмрдЬреЗ рд╣реИред"),
    ]
    
    for speaker, text in conversation:
        if speaker == "AI":
            print(f"  {Colors.CYAN}ЁЯдЦ AI: {text}{Colors.END}")
            # Generate audio for AI lines
            audio_file = f"cache/demo_bolna_ai_{hash(text) % 1000}.mp3"
            await generate_voice_audio(text, "hi", audio_file)
            print_audio(f"      Audio: {audio_file}")
        elif speaker == "Patient":
            print(f"  {Colors.WARNING}ЁЯСд Patient: {text}{Colors.END}")
        else:
            print(f"  {Colors.GREEN}ЁЯУЮ {speaker}: {text}{Colors.END}")
    
    print_section("Call Summary")
    
    summary = {
        "call_id": "call-bol-001",
        "duration": "45 seconds",
        "patient_confirmed": True,
        "dtmf_input": "1",
        "adherence_logged": True,
        "caregiver_notified": True
    }
    
    for key, value in summary.items():
        print(f"  {key}: {value}")
    
    print_success("Bolna.ai demo completed")

# ============================================================================
# DEMO 3: RETELL + VOBIZ.AI WITH SIP-REFER WARM HANDOFF
# ============================================================================

async def demo_retell_vobiz_handoff():
    """Demo Retell with Vobiz.ai and SIP-REFER warm handoff"""
    print_header("DEMO 3: RETELL + VOBIZ.AI WITH SIP-REFER WARM HANDOFF")
    
    print_section("Incoming Emergency Call")
    
    emergency = {
        "call_id": "ret-urg-001",
        "caller": "+91-98765-12345",
        "patient": "Mr. Ramesh Patel (PT-COPD-2026-042)",
        "condition": "Severe COPD - Breathlessness",
        "language": "Gujarati",
        "provider": "Vobiz.ai (Indian PSTN)"
    }
    
    for key, value in emergency.items():
        print(f"  {key}: {value}")
    
    print_section("Emergency Detection")
    
    # Patient query in Gujarati
    patient_query_gu = "ркоркирлЗ рк╢рлНрк╡рк╛рк╕ рк▓рлЗрк╡рк╛ркорк╛ркВ ркмрк╣рлБ ркдркХрк▓рлАркл ркеркИ рк░рк╣рлА ркЫрлЗ... рк╣рлБркВ рк╢рлНрк╡рк╛рк╕ рк▓ркИ ркиркерлА рк╢ркХркдрлЛ..."
    patient_query_en = "I am having a lot of difficulty breathing... I cannot breathe..."
    
    print(f"  Patient (Gujarati): {patient_query_gu}")
    print(f"  Translation: \"{patient_query_en}\"")
    
    print_warning("\n  ЁЯЪи CRITICAL EMERGENCY DETECTED")
    print("  Keywords: 'cannot breathe', 'breathlessness'")
    print("  Severity: CRITICAL")
    
    # Generate patient audio
    audio_file = "cache/demo_retell_patient_emergency.mp3"
    await generate_voice_audio(
        "ркоркирлЗ рк╢рлНрк╡рк╛рк╕ рк▓рлЗрк╡рк╛ркорк╛ркВ ркмрк╣рлБ ркдркХрк▓рлАркл ркеркИ рк░рк╣рлА ркЫрлЗ, рк╣рлБркВ рк╢рлНрк╡рк╛рк╕ рк▓ркИ ркиркерлА рк╢ркХркдрлЛ",
        "gu",
        audio_file
    )
    print_audio(f"Emergency audio: {audio_file}")
    
    print_section("SIP-REFER Warm Handoff to Human Agent")
    
    sip_message = """
    SIP/2.0 302 Moved Temporarily
    Via: SIP/2.0/WSS retell.palliative.care;branch=z9hG4bK776asdhds
    From: <sip:ai-agent@palliative.care>;tag=1928301774
    To: <sip:patient@palliative.care>;tag=a6c85cf
    Call-ID: a84b4c76e66710@pc33.palliative.care
    CSeq: 314159 INVITE
    Contact: <sip:dr-priya@palliative.care>
    Refer-To: <sip:copd-emergency@palliative.care>
    Referred-By: <sip:ai-agent@palliative.care>
    Content-Type: application/sdp
    Content-Length: 0
    
    X-Context-Transfer: {
      "patient_id": "PT-COPD-2026-042",
      "emergency_type": "respiratory_distress",
      "ai_summary": "72yo COPD patient, severe breathlessness, cyanosis risk",
      "conversation_history": "...",
      "recommended_action": "Immediate bronchodilator + oxygen assessment"
    }
    """
    
    print(sip_message)
    
    print_section("Human Agent Connection")
    
    agent = {
        "name": "Dr. Priya Sharma",
        "specialization": "Palliative Care Physician",
        "availability": "Online",
        "connection_time": "< 5 seconds"
    }
    
    print(f"  Agent: {agent['name']}")
    print(f"  Specialization: {agent['specialization']}")
    print(f"  Status: {agent['availability']}")
    print(f"  Connection: {agent['connection_time']}")
    
    print_section("Warm Handoff Message")
    
    handoff_msg_gu = """
    рк░ркорлЗрк╢ркнрк╛ркИ, ркХрлГрккрк╛ ркХрк░рлАркирлЗ ркЪрк┐ркВркдрк╛ рки ркХрк░рлЛ.
    
    рк╣рлБркВ ркдркоркирлЗ ркдрк░ркд ркЬ ркбрлЙркХрлНркЯрк░ рккрлНрк░рк┐ркпрк╛ рк╢рк░рлНркорк╛ рк╕рк╛ркерлЗ ркЬрлЛркбрлА рк░рк╣рлНркпрлЛ ркЫрлБркВ.
    
    ркдрлЗркУ ркдркорк╛рк░рк╛ рк╢рлНрк╡рк╛рк╕ркирлА ркдркХрк▓рлАркл рк╕ркоркЬрлЗ ркЫрлЗ ркЕркирлЗ ркдркоркирлЗ ркоркжркж ркХрк░рк╢рлЗред
    
    рк╢рк╛ркВркд рк░рк╣рлЛ, ркбрлЙркХрлНркЯрк░ ркЖрк╡рлА рк░рк╣рлНркпрк╛ ркЫрлЗред
    """
    
    print(f"  AI Handoff Message (Gujarati):")
    for line in handoff_msg_gu.strip().split('\n'):
        if line.strip():
            print(f"    {line}")
    
    # Generate handoff audio
    audio_file = "cache/demo_retell_handoff.mp3"
    await generate_voice_audio(
        "рк░ркорлЗрк╢ркнрк╛ркИ, ркХрлГрккрк╛ ркХрк░рлАркирлЗ ркЪрк┐ркВркдрк╛ рки ркХрк░рлЛ. рк╣рлБркВ ркдркоркирлЗ ркдрк░ркд ркЬ ркбрлЙркХрлНркЯрк░ рккрлНрк░рк┐ркпрк╛ рк╢рк░рлНркорк╛ рк╕рк╛ркерлЗ ркЬрлЛркбрлА рк░рк╣рлНркпрлЛ ркЫрлБркВред",
        "gu",
        audio_file
    )
    print_audio(f"Handoff audio: {audio_file}")
    
    print_success("SIP-REFER warm handoff completed")

# ============================================================================
# DEMO 4: WHATSAPP BOT - TWILIO SANDBOX
# ============================================================================

async def demo_whatsapp_twilio():
    """Demo WhatsApp bot using Twilio sandbox"""
    print_header("DEMO 4: WHATSAPP BOT - TWILIO SANDBOX")
    
    print_section("Twilio Sandbox Configuration")
    
    config = {
        "sandbox_number": "+1-415-523-8886",
        "join_code": "join <unique-code>",
        "webhook_url": "https://api.pallisahayak.io/webhook/whatsapp",
        "supported_features": ["Text", "Voice Notes", "Images", "Location"]
    }
    
    for key, value in config.items():
        print(f"  {key}: {value}")
    
    print_section("User Joins Sandbox")
    
    join_flow = """
    User sends: "join pallisahayak"
    
    Twilio Webhook: POST /webhook/whatsapp
    {
      "From": "whatsapp:+919876543210",
      "Body": "join pallisahayak",
      "ProfileName": "Rajesh Kumar"
    }
    
    System Response: 
    "Welcome to Palli Sahayak! ЁЯЩП\n\nSend your health query in Hindi, English, 
    or your preferred language. You can also send voice messages."
    """
    
    print(join_flow)
    
    print_section("Sample Conversation")
    
    conversation = [
        ("User", "My father has severe back pain. He is on chemotherapy."),
        ("System", "I understand. Let me check our clinical guidelines..."),
        ("System", """
        Based on WHO Cancer Pain Guidelines (Evidence Level A):
        
        1. Morphine 5-10mg every 4 hours as needed
        2. If pain persists, consult your oncologist
        3. Monitor for constipation
        
        ЁЯЯв Confidence: 94%
        ЁЯУЪ Source: WHO + Max Healthcare protocols
        """),
        ("User", "/remind Morphine 08:00,20:00 10mg"),
        ("System", "тЬЕ Reminder set for Morphine 10mg at 08:00 and 20:00."),
        ("System", "You'll receive a voice call reminder."),
    ]
    
    for sender, message in conversation:
        if sender == "System":
            print(f"\n  {Colors.CYAN}ЁЯдЦ {sender}:{Colors.END}")
            for line in message.strip().split('\n'):
                print(f"    {line}")
        else:
            print(f"\n  {Colors.WARNING}ЁЯСд {sender}:{Colors.END}")
            print(f"    {message}")
    
    print_section("Voice Note Feature")
    
    voice_flow = """
    User sends: [Voice Note - 15 seconds in Hindi]
    
    System Processing:
    1. Download audio from Twilio Media URL
    2. Transcribe using Groq Whisper (hi-IN)
    3. Query RAG pipeline
    4. Generate response
    5. Convert to voice using Edge TTS
    6. Send voice note back
    
    Total latency: ~3-4 seconds
    """
    
    print(voice_flow)
    
    print_success("WhatsApp Twilio demo completed")

# ============================================================================
# SUMMARY
# ============================================================================

async def print_summary():
    """Print summary of all demos"""
    print_header("VOICE AI DEMO SUMMARY")
    
    providers = {
        "Gemini Live API": {
            "use_case": "Web-based voice conversations",
            "best_for": "Real-time streaming, natural conversations",
            "audio_format": "PCM 16kHz/24kHz",
            "languages": "hi-IN, en-IN, ta-IN, mr-IN"
        },
        "Bolna.ai": {
            "use_case": "Phone calls via Twilio",
            "best_for": "Production telephony, custom voice agents",
            "stack": "Deepgram тЖТ GPT-4o тЖТ ElevenLabs",
            "languages": "7+ Indian languages"
        },
        "Retell + Vobiz.ai": {
            "use_case": "Indian PSTN (+91) with SIP-REFER",
            "best_for": "Warm handoff to human agents",
            "feature": "SIP-REFER for seamless transfer",
            "compliance": "Indian telecom regulations"
        },
        "WhatsApp + Twilio": {
            "use_case": "Text and voice messaging",
            "best_for": "Async communication, reminders",
            "features": "Voice notes, images, location",
            "sandbox": "Easy testing environment"
        }
    }
    
    for provider, details in providers.items():
        print(f"\n  {Colors.BOLD}{provider}{Colors.END}")
        for key, value in details.items():
            print(f"    {key}: {value}")
    
    print(f"\n{Colors.GREEN}{'='*70}{Colors.END}")
    print(f"{Colors.GREEN}{Colors.BOLD}ЁЯОп All Voice AI Demos Completed Successfully!{Colors.END}")
    print(f"{Colors.GREEN}{'='*70}{Colors.END}\n")

# ============================================================================
# MAIN
# ============================================================================

async def main():
    """Run all voice AI demos"""
    print(f"\n{Colors.BOLD}{Colors.HEADER}")
    print("тХФ" + "="*68 + "тХЧ")
    print("тХС" + " PALLI SAHAYAK - VOICE AI DEMO SUITE ".center(68) + "тХС")
    print("тХС" + " Gemini Live | Bolna | Retell+Vobiz | WhatsApp ".center(68) + "тХС")
    print("тХЪ" + "="*68 + "тХЭ")
    print(f"{Colors.END}\n")
    
    print(f"Timestamp: {datetime.now().isoformat()}")
    print(f"Audio Generation: Edge TTS (Microsoft)")
    print(f"Languages: Hindi, Gujarati, English, Bengali, Tamil")
    print()
    
    # Ensure cache directory exists
    Path("cache").mkdir(exist_ok=True)
    
    try:
        # Run all demos
        await demo_gemini_live()
        await demo_bolna()
        await demo_retell_vobiz_handoff()
        await demo_whatsapp_twilio()
        await print_summary()
        
    except Exception as e:
        print(f"\n{Colors.FAIL}Demo failed: {e}{Colors.END}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

if __name__ == "__main__":
    asyncio.run(main())
